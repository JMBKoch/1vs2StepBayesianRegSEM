---
title             : "Getting a Step Ahead: Using the Regularized Horseshoe Prior to Select Cross-Loadings in Bayesian CFA"
shorttitle        : "Getting a Step Ahead: Using the Regularized Horseshoe Prior to Select Cross-Loadings in Bayesian CFA"
wordcount         : "X"
bibliography      : ["refs.bib"]
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no
documentclass     : "apa6"
output            : 
  papaja::apa6_pdf:
    includes:
      in_header: "preamble.tex"
    latex_engine: xelatex
editor_options: 
  markdown: 
    wrap: 72
---

```{=tex}
% move text to bottom of page
\vfill
Research Reports \\
Michael Koch (6412157)\\
Methodology and Statistics for the Behavioral, Biomedical, and Social Sciences \\
Supervisor: Dr. Sara van Erp \\ 
Email: j.m.b.koch@students.uu.nl \\
Word Count: 2500 \\
Intented Journal of Publication: Structural Equation Modeling \\

% make page numbers start from second page 
\pagenumbering{arabic}
\setcounter{page}{0}
\thispagestyle{empty}
% make page numbers from second page 
\pagestyle{plain}
```
```{r setup, include = FALSE}
library("papaja")
library(LaplacesDemon) # for horseshoe density 
library(ggplot2)
library(magrittr)
library(jtools) # for apa ggplot theme
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(0704)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

\clearpage

The art of statistical modeling revolves around finding an appropriate simplification, i.e., a model, of a true data-generating process (TBA REF). Hereby, a fundamental trade-off arises between model-simplicity and model-complexity. On the one hand, models need to be  simple enough to be (1) identified (i.e., estimate-able with the information available in the data); (2) interpretable; and (3) generalizable (i.e., not over-fitted, hence having enough variance). On the other hand, models need to be complex enough (have enough parameters) to accurately represent the true data generating process (i.e., to not be too biased) (ADD REF). 

In the context of confirmatory factor analysis (CFA), an essential tool for modeling measurement structures, it is common practice to deal with this fundamental trade-off by imposing a so-called simple structure (ADD REF). Here, factor loadings that relate items to factors that they theoretically do not belong to, are fixed to zero to identify the model (see Figure 1 for an example of a 2-factor model with simple structure). This practice often leads to poor model fit, which forces researchers to free some cross-loadings after the fact based on empirical grounds (modification indices) to improve fit. This practice is, however, highly flawed, as it risks capitalization of chance and thereby over-fitting (REF), hence ending up with a model that does not generalize well to other datasets from the same population. 

## Bayesian Regularized SEM

As solution to the issue, @muthen_bayesian_2012 proposed that rather than fixing *all* cross-loadings to zero, one should should assume that *most* cross-loadings are zero. Formally, this is achieved by setting the so-called Small Variance Normal Prior (SVNP) for the cross-loadings, which is a normal distribution with mean zero and a very small variance (e.g.: $\sigma^2$ = 0.1, $\sigma^2$ = 0.01, $\sigma^2$ = 0.001). This prior has a large peak at zero, and very thin tails (see Figure 2). Hence, it attaches large prior mass to cross-loadings of or near zero, while attaching almost no prior mass to cross-loadings further from zero. Consequently, all cross-loadings in the model are shrunken. The larger the priorâ€™s variance, the more admissive the model is in the amount of deviation from zero it allows. Lu and colleguaes note that this approach is simply a form of regularization, where cross-loadings are regularized in an attempt to identify and select relevant cross-loadings as non-zero, such that one ends up with a sparse model.  

An issue with muthen_bayesian_2012's approach is that not only the cross-loadings close to zero that are considered irrelevant are shrunken to zero, as desired, but also the ones further from zero are shrunken towards zero, which introduces bias [@lu_bayesian_2016]. First, bias naturally occurs in the large cross-loadings itself. However, given that the parameters of a model are esitmated conditionally on another, also in other parameters, such as factor-correlations, or main-loadings, substantial bias can arise. Consquently, the method requires a two-step approach. First, the model is estimated with the SVNP. Then the model is re-estimated, with cross-loadings that have been selected to be zero in the previous step are fixed to zero, and the remaining cross-loadings are estimated without shrinkage, avoiding the bias in the model of the previous step. This process is tedious, computationally expensive, and adds a number of undesired researchers degrees of freedom. Therefore, alternative priors need to be identified that can outperform the Small VarianceNormal Prior in a single step. The literature on regularization in a regression context (see @van_erp_shrinkage_2019 for an overview) provides a variety of promising candidates for achieving this end. 

## Spike-and-Slab Prior

One promising regularization prior for the purpose of selecting cross-loadings in regularized Bayesian SEM is the so-called Spike-and-Slab Prior (also known as ). This prior is a discrete mixture prior...? 

 - Decription prior also in mathematical terms 

 
Indeed, @lu_bayesian_2016 found that this prior is doing well in identifying truly non-zero cross-loadings as such. However, the big caveat of this method is that the prior cannot be implemented in STAN, the MCMC-sampling package that is most appropriate to estimated regularized SEM models due to its excellent ability to estimate highly-dimensional models. 

## The Regularized Horseshoe Prior (RHSP)

The reason that the Spike-and-Slab Prior is unavailable is

(see @betancourt_conceptual_2018). A promising alternative, that is a mixture of fully continous distributions, and thus employable in STAN, is the so-called Reularized Horseshoe Prior (RHSP).

- Extension of Horseshoe Prior [@carvalho_horseshoe_2010]
- Main idea: global shrinkage parameter (shrinking all cross-loadings to zero) and local shrinkage parameter (allowing the relevant cross-loadings to escape the shrinkage) [@piironen_sparsity_2017]
- Formally:
- Regularized adds the slab, which shrinks ALL cross-loadings at least a little bit, to avoid identification issues [see @ghosh_use_2018]


- Mathematical formulation 


Figure 3 illustrates the two priors, with ... hyper-parameter configurations

# The current study 

While the Regularized Horseshoe Prior has been shown to perform excellently in the selection of relevant predictors in regression [@piironen_sparsity_2017; @van_erp_shrinkage_2019], no previous research has validated its performance in selecting relevant cross-loadings in CFA. To fill this gap, the aim of this study is to compare the RHSP to the SVNP in their performance in selecting the true factor structure in CFA.

## Analytic Strategy

In order to assess the performance of the SVNP in regularizing cross-loadings in Bayesian Regularized SEM, a Monte Carlo simulation study was conduced using STAN [@stan_development_team_stan_2021]. The models were be sampled using the No-U-Turn-Sampler [@homan_no-u-turn_2014], with two chains, a burnin-period of 2000 and a chain-length of 4000. These sampling parameters were identified to be required for the RHSP to reach convergence, and were therefore also used for the SVNP in order to ensure a comparability. 

The datasets were simulated based on a true 2-factor model, which is summarized in Figure 2. We varied the magnitude of the two non-zero cross-loadings between 0.2 and 0.5. Next, we varied the sample sizes of the simulated datasets between N = 100 and N = 200. This choice was made based on the fact that for such simple factor models researchers would be unlikely to collected larger sample sizes in practice. Finally, based on the recommodations of @muthen_bayesian_2012, we included three levels of the hyperparameter $sigma^2$: 0.001, 0.01, 0.1). 

![Figure 2](~/1vs2StepBayesianRegSEM/Rmd/figures/model.png)

A summary of all conditions that is summarized below in Table 1.

- Table 1: Overzicht condities in tabel 


As main outcomes, we considered the (mean absolute) bias and the mean squared error (MSE) in all estimated model paramters. 

- Main outcomes: (mean absolute) bias, MSE, Power, Type I error rate
  - different selection rules regarding the latter two:  tresholds, credible intervals [@zhang_criteria_2021]




```{r dev='cairo_pdf', include=T, echo=F, warning=F, fig.cap="Density Plots of the Regularization Priors of Interest"}
# Make Figure 1 with 
ndraws <- 5e+05 # 10000 draws
# sample Small Variance Normal Prior
smallVar <- rnorm(ndraws, mean = 0, sd = 0.1)

# sample regularized horseshoe prior
regHs <- rep(NA, ndraws)
for(i in 1:ndraws){
  c2 <- rinvgamma(1, shape=0.5, scale=1)
  lambda <- rhalfcauchy(1, scale=1)
  tau <- rhalfcauchy(1, scale=1)
  lambda2_tilde <- c2 * lambda^2/(c2 + tau^2*lambda^2)
  regHs[i] <- rnorm(1, 0, sqrt(tau^2*lambda2_tilde))
}

# make plot
data.frame(dens = c(smallVar, regHs), 
          prior = as.factor(rep(c("Small Variance Normal Prior (\u03c3\u00B2 = 0.01)", "Regularized Horseshoe Prior"), each = ndraws)),
          asymp = rep(0, ndraws)) %>% 
  ggplot(aes(x = dens, fill = prior, linetype = prior)) + 
  geom_density(alpha = .5)+
  geom_vline(aes(xintercept = asymp), linetype = "dashed") +
  xlim(-.5, .5)+
  labs(x = "Size Cross-Loading", title = NULL)+
  theme_apa(legend.pos = "bottom")
```

\clearpage

```{tex}
\end{itemize}
```

# References 
\ 
```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```

::: {#refs custom-style="Bibliography"}
:::

\endgroup

\clearpage

```{=tex}
\begingroup
\setlength{\parskip}{0in}
\setlength{\parindent}{-0.27in}
\setlength{\leftskip}{0.5in}
```

